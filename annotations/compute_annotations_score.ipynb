{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  comment_id  abstract_id        annotator                     score comment\n",
       "0        [1]            1     Dey,  Gautam  conclusions_nounchange_1     NaN\n",
       "1        [2]            1   Jessica  Polka      context_nounchange_1     NaN\n",
       "2        [3]            1      Mate  Palfy     context_nounchange_1+     NaN\n",
       "3        [4]            1  jonathon coates         context_effect-_1     NaN\n",
       "4        [5]            1   Jessica  Polka        conclusion_stat-_1     NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_id</th>\n      <th>abstract_id</th>\n      <th>annotator</th>\n      <th>score</th>\n      <th>comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1]</td>\n      <td>1</td>\n      <td>Dey,  Gautam</td>\n      <td>conclusions_nounchange_1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[2]</td>\n      <td>1</td>\n      <td>Jessica  Polka</td>\n      <td>context_nounchange_1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[3]</td>\n      <td>1</td>\n      <td>Mate  Palfy</td>\n      <td>context_nounchange_1+</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[4]</td>\n      <td>1</td>\n      <td>jonathon coates</td>\n      <td>context_effect-_1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[5]</td>\n      <td>1</td>\n      <td>Jessica  Polka</td>\n      <td>conclusion_stat-_1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "annotations_df = pd.read_csv(\"annotations.tsv\", sep='\\t') \n",
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "184\n"
     ]
    }
   ],
   "source": [
    "max_id = max([int(x) for x in set(annotations_df[\"abstract_id\"])])\n",
    "print (max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "184\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'10.1101/869313'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "annotations_df = annotations_df[annotations_df['score'].notna()]\n",
    "\n",
    "dois = open(\"dois.txt\",\"r\").read().strip().split(\"\\n\")\n",
    "dois = {x+1:dois[x] for x in range(len(dois))}\n",
    "\n",
    "print (len(dois))\n",
    "dois[184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " normalise_sections = {'conclusion':\"conclusions\",\n",
    " 'conclusion':\"conclusions\",\n",
    " 'conclusion  ':\"conclusions\",\n",
    " 'conclusions':\"conclusions\",\n",
    " 'concusions':\"conclusions\",\n",
    " 'contex':\"context\",\n",
    " 'context':\"context\",\n",
    " 'context  ':\"context\",\n",
    " 'context  removed':\"context\",\n",
    " 'countext':\"context\",\n",
    " 'new':\"new\",\n",
    " 'reslts':'results',\n",
    " 'resuls':'results',\n",
    " 'result':'results',\n",
    " 'results':'results',\n",
    " 'results/context':'results/context',\n",
    " 'resutls':'results',\n",
    " 'resuts':'results'}\n",
    "\n",
    "normalise_labels = {'nounchange': 'nounchange', 'effect-': 'effect', 'stat-': 'stat', 'added': 'added', 'removed': 'removed', 'stat+': 'stat', 'stat-1': 'stat', 'effect+': 'effect', 'statinfo': 'stat', 'effectreverse': 'effectreverse', 'aded': 'added', 'effectt+': 'effect', 'nouchange': 'nounchange', 'effect': 'effect', 'results': 'results', 'nounchage': 'nounchange', 'stat': 'stat', 'ef': 'effect', 'added  ': 'added', 'emoved': 'removed', 'remove': 'removed'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_ann = open(\"raw_annotations.csv\",\"w\")\n",
    "out_ann.write(\"page_id, doi,annotator,section,label,score\\n\")\n",
    "\n",
    "final_columns = {}\n",
    "for id in range(1,185):\n",
    "    overall_score = {x:{p:[] for z,p in normalise_labels.items()} for y,x in normalise_sections.items()}\n",
    "    scores = annotations_df.loc[annotations_df['abstract_id'] == id][\"score\"].tolist()\n",
    "    annotators = annotations_df.loc[annotations_df['abstract_id'] == id][\"annotator\"].tolist()\n",
    "    scores = [[annotators[x],scores[x]] for x in range(len(scores)) if \"_\" in scores[x]]\n",
    "    doi = dois[id]\n",
    "    for el in scores:\n",
    "            ann = el[0].replace(\",\",\" \")\n",
    "            score = el[1]\n",
    "            score = score.replace(\" \",\"\")\n",
    "            score = score.strip()\n",
    "\n",
    "            if len(score.split(\"_\"))>2 and score.split(\"_\")[0] in normalise_sections:\n",
    "                section = normalise_sections[score.split(\"_\")[0]]\n",
    "                label = normalise_labels[score.split(\"_\")[1]]\n",
    "                \n",
    "                # check if there is a modifier in the label\n",
    "                modifier = [x for x in score.split(\"_\")[1] if x == \"+\" or x == \"-\"]\n",
    "                sc = score.split(\"_\")[-1].strip()\n",
    "                try:\n",
    "                    int_sc = int(''.join(c for c in sc if c.isdigit()))\n",
    "                # this happens if the annotator forgot to assign a value, we add 1 here\n",
    "                except ValueError:\n",
    "                    sc = \"1\"\n",
    "                    int_sc = 1\n",
    "\n",
    "                if len(modifier)>0:\n",
    "                    modifier = modifier[0]\n",
    "                    # we check if there is a modifier in the score\n",
    "                    sc_modifier = [x for x in sc if x == \"+\" or x == \"-\"]\n",
    "                    if len(sc_modifier)>0 and modifier != sc_modifier[0]:\n",
    "                        # so if the modifier in the label is inconsistent (it happens 5 times)\n",
    "                        # for the moment I am always considering it negative\n",
    "                        modifier = \"-\"\n",
    "\n",
    "                # apply the modifier\n",
    "                if modifier == \"-\":\n",
    "                    int_sc = -int_sc\n",
    "\n",
    "                out_ann.write(str(id)+\",\"+doi+\",\"+ann+\",\"+section+\",\"+label+\",\"+str(int_sc)+\"\\n\")\n",
    "                overall_score[section][label].append(sc)\n",
    "\n",
    "\n",
    "    for section,labels in overall_score.items():\n",
    "        for label,score in labels.items():\n",
    "            \n",
    "            if section+\"_\"+label not in final_columns:\n",
    "                final_columns[section+\"_\"+label] =[score]\n",
    "            else:\n",
    "                final_columns[section+\"_\"+label].append(score)\n",
    "out_ann.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns = open(\"col.csv\",\"w\")\n",
    "\n",
    "for column in final_columns.keys():\n",
    "    output_columns.write(column+\",\")\n",
    "output_columns.write(\"\\n\")\n",
    "\n",
    "for i in range(186):\n",
    "    for c,v in final_columns.items():\n",
    "        s = v[i]\n",
    "        s = \" \".join([str(n) for n in s])\n",
    "        output_columns.write(s+\",\")\n",
    "    output_columns.write(\"\\n\")\n",
    "output_columns.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(\"contains_2.txt\",\"w\")\n",
    "for id in range(186):\n",
    "    scores = annotations_df.loc[annotations_df['abstract_id'] == id][\"score\"]\n",
    "    scores = [x.split(\"_\")[-1].strip() for x in scores if \"_\" in x]\n",
    "    #scores = [x for x in scores if \"2\" in x]\n",
    "    scores = [x for x in scores if \"2\" in x]\n",
    "    if len(scores)>0:\n",
    "        out.write(str(len(scores))+\"\\n\")\n",
    "    else:\n",
    "        out.write(\"0\\n\")\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(\"sum.txt\",\"w\")\n",
    "for id in range(186):\n",
    "    scores = annotations_df.loc[annotations_df['abstract_id'] == id][\"score\"]\n",
    "    scores = [x.split(\"_\")[-1].strip() for x in scores if \"_\" in x]\n",
    "    #scores = \" \".join([x for x in scores if \"2\" in x or \"1\" in x])\n",
    "    scores = [x for x in scores if \"-\" not in x]\n",
    "    scores = [int(y) for x in scores if \"2\" in x or \"1\" in x for y in x if y.isnumeric()]\n",
    "    print (scores)\n",
    "    if len(scores)>0:\n",
    "        out.write(str(sum(scores))+\"\\n\")\n",
    "    else:\n",
    "        out.write(\"0\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}